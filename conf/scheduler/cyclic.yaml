# @package _group_
class_name: torch.optim.lr_scheduler.CyclicLR
step: step
params:
  base_lr: ${training.lr}
  max_lr: 0.1
